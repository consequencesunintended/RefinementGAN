{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/consequencesunintended/RefinementGAN/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9251vKW7YB39"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFKhRrCjXhBV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation, Reshape\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjghHFOrXhBW"
   },
   "outputs": [],
   "source": [
    "print (\"Tensorflow version: {}\".format( tf.__version__ ) )\n",
    "print (\"Keras version: {}\".format( kr.__version__ ) )\n",
    "print (\"Numpy version: {}\".format( np.__version__ ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nm5sXD4nYHsX"
   },
   "outputs": [],
   "source": [
    "DIMENSION = 64\n",
    "FC_DIM = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1000\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "MODEL_NUMBER = 1 # use model numbers 1-3 for different variations of the architecture\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_TEST_IMG = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIqUL3dSYK4Z"
   },
   "outputs": [],
   "source": [
    "data_dir = \"dataset/real images/*.jpg\"\n",
    "real_images_ds = tf.data.Dataset.list_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3IvyV9oXhBX"
   },
   "outputs": [],
   "source": [
    "data_dir = \"dataset/synthetic images/*.jpg\"\n",
    "synthetic_images_ds = tf.data.Dataset.list_files(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cf7Kf8wqCwU8"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJ9U-km8C3ku"
   },
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [DIMENSION, DIMENSION])\n",
    "\n",
    "    img_8 = tf.image.resize(img, [DIMENSION // 8, DIMENSION // 8])\n",
    "    img_4 = tf.image.resize(img, [DIMENSION // 4, DIMENSION // 4])\n",
    "    img_2 = tf.image.resize(img, [DIMENSION // 2, DIMENSION // 2])\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img_8 = tf.image.flip_left_right(img_8)\n",
    "        img_4 = tf.image.flip_left_right(img_4)\n",
    "        img_2 = tf.image.flip_left_right(img_2)\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        \n",
    "            \n",
    "    return img_2, img_4, img_8, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWCInvghC6lB"
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img_2, img_4, img_8, img = decode_img(img)\n",
    "    return img_2, img_4, img_8, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4DVVYPYC8p0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_images_ds = real_images_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "synthetic_images_ds = synthetic_images_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYpPdZCvXhBZ"
   },
   "outputs": [],
   "source": [
    "train_dataset = real_images_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8shCfRRmXhBa"
   },
   "outputs": [],
   "source": [
    "test_dataset = synthetic_images_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwO8UX5ODIXC"
   },
   "outputs": [],
   "source": [
    "NUM_IMAGES = len(real_images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwFbV3uPXhBa"
   },
   "outputs": [],
   "source": [
    "NUM_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSpp81TAYaFz"
   },
   "outputs": [],
   "source": [
    "syn_img_2, syn_img_4, syn_img_8, syn_img = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1vlvOt8XhBb"
   },
   "outputs": [],
   "source": [
    "syn_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UC-OZ3xzZOXl"
   },
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, NUM_TEST_IMG, figsize=(DIMENSION,DIMENSION))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img.numpy())                       \n",
    "        ax.axis('off')    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoZj-728ZPl6"
   },
   "outputs": [],
   "source": [
    "plotImages(syn_img[:NUM_TEST_IMG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEvwTdQOXhBb"
   },
   "outputs": [],
   "source": [
    "plotImages(syn_img_2[:NUM_TEST_IMG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPvho1DnXhBc"
   },
   "outputs": [],
   "source": [
    "plotImages(syn_img_4[:NUM_TEST_IMG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FfPGdawXhBc"
   },
   "outputs": [],
   "source": [
    "plotImages(syn_img_8[:NUM_TEST_IMG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSXH1zxKXhBc"
   },
   "outputs": [],
   "source": [
    "class ResizeNN(Layer):\n",
    "    def __init__(self, image_size=(512, 512), **kwargs):\n",
    "        self.image_size = image_size[0], image_size[1]\n",
    "        super(ResizeNN, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.image.resize(inputs, self.image_size, method='nearest')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.image_size[0], self.image_size[1], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WsCRkBRXhBc"
   },
   "outputs": [],
   "source": [
    "def disc_encoder():\n",
    "    input_shape = [DIMENSION,DIMENSION,3]\n",
    "    kernel= 3\n",
    "    filters = 64\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(inputs)\n",
    "    block_1 = tf.nn.elu(block_1)\n",
    "    \n",
    "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
    "    block_1 = tf.nn.elu(block_1)\n",
    "    block_1 = ResizeNN([DIMENSION, DIMENSION])(block_1)\n",
    "    \n",
    "    print(\"Encoder - Block 1 Created!\")\n",
    "    \n",
    "    block_2 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
    "    block_2 = tf.nn.elu(block_2)\n",
    "    \n",
    "    block_2 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
    "    block_2 = tf.nn.elu(block_2)\n",
    "    block_2 = ResizeNN([DIMENSION//2, DIMENSION//2])(block_2)\n",
    "    \n",
    "    print(\"Encoder - Block 2 Created!\")\n",
    "    \n",
    "    block_3 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
    "    block_3 = tf.nn.elu(block_3)\n",
    "    \n",
    "    block_3 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
    "    block_3 = tf.nn.elu(block_3)\n",
    "    block_3 = ResizeNN([DIMENSION//4, DIMENSION//4])(block_3)\n",
    "    \n",
    "    print(\"Encoder - Block 3 Created!\")\n",
    "    \n",
    "    block_4 = Convolution2D(4*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
    "    block_4 = tf.nn.elu(block_4)\n",
    "    \n",
    "    block_4 = Convolution2D(4*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
    "    block_4 = tf.nn.elu(block_4)\n",
    "    block_4 = ResizeNN([DIMENSION//8, DIMENSION//8])(block_4)\n",
    "    \n",
    "    block_4_flatten  = Flatten()(block_4)\n",
    "    dense_1 = Dense(8*8*4*filters)(block_4_flatten)\n",
    "    dense_2 = Dense(FC_DIM)(dense_1)\n",
    "\n",
    "    outputs = (dense_2)   \n",
    "    \n",
    "    print(\"Encoder - Block 4 Created!\")\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"disc_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuhguzRIXhBd"
   },
   "outputs": [],
   "source": [
    "def disc_decoder():\n",
    "    kernel= 3\n",
    "    filters = 64\n",
    "\n",
    "    inputs = Input(shape=(FC_DIM,))\n",
    "    \n",
    "    dense_1 = Dense(8*8*filters)(inputs)\n",
    "    dens_1_reshaped = Reshape([8,8,filters])(dense_1)\n",
    "    \n",
    "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(dens_1_reshaped)\n",
    "    block_1 = tf.nn.elu(block_1)\n",
    "    \n",
    "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
    "    block_1 = tf.nn.elu(block_1)\n",
    "    block_1 = ResizeNN([DIMENSION//4, DIMENSION//4])(block_1)\n",
    "    \n",
    "    print(\"Decoder - Block 1 Created!\")\n",
    "    \n",
    "    block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
    "    block_2 = tf.nn.elu(block_2)\n",
    "    \n",
    "    block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
    "    block_2 = tf.nn.elu(block_2)\n",
    "    block_2 = ResizeNN([DIMENSION//2, DIMENSION//2])(block_2)\n",
    "    \n",
    "    print(\"Decoder - Block 2 Created!\")\n",
    "    \n",
    "    block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
    "    block_3 = tf.nn.elu(block_3)\n",
    "    \n",
    "    block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
    "    block_3 = tf.nn.elu(block_3)\n",
    "    block_3 = ResizeNN([DIMENSION, DIMENSION])(block_3)\n",
    "    \n",
    "    print(\"Decoder - Block 3 Created!\")\n",
    "    \n",
    "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
    "    block_4 = tf.nn.elu(block_4)\n",
    "    \n",
    "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
    "    block_4 = tf.nn.elu(block_4)\n",
    "    \n",
    "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
    "    block_4 = tf.nn.elu(block_4)    \n",
    "    \n",
    "    block_4 = Convolution2D(3, (kernel, kernel), padding=\"same\")(block_4)\n",
    "    block_4 = Activation(\"sigmoid\")(block_4)\n",
    "\n",
    "    outputs = (block_4)   \n",
    "    \n",
    "    print(\"Decoder - Block 4 Created!\")\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"disc_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQ9B7DFWZUKG"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    \n",
    "    e_model = disc_encoder()\n",
    "    d_model = disc_decoder()\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(e_model)\n",
    "    model.add(d_model)\n",
    "    \n",
    "    print(\"Discriminator - Model Generated!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQfVloBPZWSb"
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eqYgUcGZQoN"
   },
   "outputs": [],
   "source": [
    "def make_generator_model( model_number = 1 ):\n",
    "    kernel= 3\n",
    "    filters = 64\n",
    "\n",
    "    input_image_8 = Input(shape=[DIMENSION//8,DIMENSION//8,3])\n",
    "    input_image_4 = Input(shape=[DIMENSION//4,DIMENSION//4,3])\n",
    "    input_image_2 = Input(shape=[DIMENSION//2,DIMENSION//2,3])\n",
    "    input_image   = Input(shape=[DIMENSION,DIMENSION,3])\n",
    "    \n",
    "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(input_image_8)\n",
    "    block_1 = tf.nn.elu(block_1)\n",
    "    \n",
    "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
    "    block_1 = tf.nn.elu(block_1)\n",
    "    block_1 = ResizeNN([DIMENSION//4, DIMENSION//4])(block_1)\n",
    "    \n",
    "    print(\"Generator/Refiner - Block 1 Created!\")\n",
    "    \n",
    "    if ( model_number == 2 or model_number == 3 ):\n",
    "        block_2 = concatenate([input_image_4, block_1])\n",
    "        block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
    "    else:\n",
    "        block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
    "    block_2 = tf.nn.elu(block_2)\n",
    "    \n",
    "    block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
    "    block_2 = tf.nn.elu(block_2)\n",
    "    block_2 = ResizeNN([DIMENSION//2, DIMENSION//2])(block_2)\n",
    "    \n",
    "    print(\"Generator/Refiner - Block 2 Created!\")\n",
    "    \n",
    "    if ( model_number == 3 ):\n",
    "        block_3 = concatenate([input_image_2, block_2])\n",
    "        block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)        \n",
    "    else:\n",
    "        block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)        \n",
    "        \n",
    "    block_3 = tf.nn.elu(block_3)\n",
    "    \n",
    "    block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
    "    block_3 = tf.nn.elu(block_3)\n",
    "    block_4 = ResizeNN([DIMENSION, DIMENSION])(block_3)\n",
    "    \n",
    "    print(\"Generator/Refiner - Block 3 Created!\")\n",
    "\n",
    "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
    "    block_4 = tf.nn.elu(block_4)\n",
    "    \n",
    "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
    "    block_4 = tf.nn.elu(block_4)\n",
    "    \n",
    "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
    "    block_4 = tf.nn.elu(block_4)    \n",
    "    \n",
    "    block_4 = Convolution2D(3, (kernel, kernel), padding=\"same\")(block_4)\n",
    "    block_4 = Activation(\"sigmoid\")(block_4)\n",
    "\n",
    "    outputs = (block_4)   \n",
    "    \n",
    "    print(\"Generator/Refiner - Model Generated!\")\n",
    "\n",
    "    return Model(inputs=[input_image, input_image_2, input_image_4, input_image_8], outputs=outputs, name=\"refiner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EdxRbScXhBg"
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model(MODEL_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqkOoKopXhBg"
   },
   "outputs": [],
   "source": [
    "def calculate_LGAN(v, Dv):\n",
    "    \n",
    "    diff = tf.abs(v - Dv)\n",
    "    \n",
    "    return tf.reduce_mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k70E4DVOXhBg"
   },
   "outputs": [],
   "source": [
    "def get_loss(k_t, x, D_x, G_z, D_G_z, outputs):\n",
    "    \n",
    "    lambda_r = 0.2\n",
    "    lambda_k = 0.001\n",
    "    gamma = 0.75\n",
    "    \n",
    "    LGAN_x = calculate_LGAN(x, D_x)\n",
    "    LGAN_gz = calculate_LGAN(G_z, D_G_z)\n",
    "    \n",
    "    D_v_hr = outputs\n",
    "    G_v_lr = G_z\n",
    "    LRCN_z = calculate_LGAN(D_v_hr, G_v_lr)\n",
    "    \n",
    "    D_loss = LGAN_x - k_t * LGAN_gz\n",
    "    G_loss = ( 1.0 - lambda_r ) * LGAN_gz + ( lambda_r ) * LRCN_z\n",
    "          \n",
    "    k_tp = k_t + lambda_k * (gamma * LGAN_x - LGAN_gz)\n",
    "        \n",
    "    return G_loss, D_loss, k_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fiBmw-mZcgg"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE,)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7GnY6P_Zf1h"
   },
   "outputs": [],
   "source": [
    " eval_input = [syn_img[:NUM_TEST_IMG], syn_img_2[:NUM_TEST_IMG], syn_img_4[:NUM_TEST_IMG], syn_img_8[:NUM_TEST_IMG]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdPXW8BrZh6y"
   },
   "outputs": [],
   "source": [
    "def train_step(k_t, values):\n",
    "    \n",
    "    inputs_2, inputs_4, inputs_8, outptuts = values\n",
    "    \n",
    "    D_gen_in = [outptuts, inputs_2, inputs_4, inputs_8]\n",
    "    D_real_in = outptuts\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(D_gen_in, training=True)\n",
    "\n",
    "        d_generated_images = discriminator(generated_images, training=True)\n",
    "        discrimanted_images = discriminator(D_real_in, training=True)\n",
    "                \n",
    "        gen_loss, disc_loss, k_t = get_loss(k_t, D_real_in, discrimanted_images, generated_images, d_generated_images, outptuts)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)    \n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return k_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaJk2q2hZuD7"
   },
   "outputs": [],
   "source": [
    "def display_refined_images(model, synthetic_images):\n",
    "    \n",
    "    predictions = model(synthetic_images, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.suptitle('Synthetic Images', fontsize=16)\n",
    "    for i in range(synthetic_images[0].shape[0]):\n",
    "        \n",
    "        plt.subplot(4, 4, i+1)        \n",
    "        plt.imshow(synthetic_images[0][i, :, :] )            \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.suptitle('Refined Images', fontsize=16)\n",
    "    for i in range(predictions.shape[0]):\n",
    "        \n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :] )            \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8YH9c0CZwZD"
   },
   "outputs": [],
   "source": [
    "STEP_SIZE = NUM_IMAGES // BATCH_SIZE\n",
    "\n",
    "def train(epochs):\n",
    "    \n",
    "    k_t = 0.0    \n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        g_loss = 0\n",
    "        d_loss = 0\n",
    "\n",
    "        for _ in range(STEP_SIZE):\n",
    "            \n",
    "            k_t = min(max(k_t, 0.0), 1.0)\n",
    "            \n",
    "            k_t = train_step(k_t, next(iter(train_dataset)))\n",
    "            step += 1\n",
    "            \n",
    "            if ( step % 100 == 0 ):\n",
    "                \n",
    "                display.clear_output(wait=True)\n",
    "                display_refined_images(generator, eval_input)\n",
    "                        \n",
    "        print ('{} seconds for epoch {}/{}'.format(time.time()-start, epoch + 1, epochs))\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display_refined_images(generator, eval_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJNQT51KZyL3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7q3HA__XhBi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "model.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
