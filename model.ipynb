{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/consequencesunintended/RefinementGAN/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9251vKW7YB39"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras as kr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFKhRrCjXhBV"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Activation, Reshape\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from keras.engine.topology import Layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjghHFOrXhBW"
      },
      "source": [
        "print (\"Tensorflow version: {}\".format( tf.__version__ ) )\n",
        "print (\"Keras version: {}\".format( kr.__version__ ) )\n",
        "print (\"Numpy version: {}\".format( np.__version__ ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm5sXD4nYHsX"
      },
      "source": [
        "DIMENSION = 64\n",
        "FC_DIM = 128\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 1000\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "MODEL_NUMBER = 1 # use model numbers 1-3 for different variations of the architecture\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_TEST_IMG = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIqUL3dSYK4Z"
      },
      "source": [
        "data_dir = \"data/real images/*.jpg\"\n",
        "real_images_ds = tf.data.Dataset.list_files(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3IvyV9oXhBX"
      },
      "source": [
        "data_dir = \"data/synthetic images/*.jpg\"\n",
        "synthetic_images_ds = tf.data.Dataset.list_files(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf7Kf8wqCwU8"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ9U-km8C3ku"
      },
      "source": [
        "def decode_img(img):\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, [DIMENSION, DIMENSION])\n",
        "\n",
        "    img_8 = tf.image.resize(img, [DIMENSION // 8, DIMENSION // 8])\n",
        "    img_4 = tf.image.resize(img, [DIMENSION // 4, DIMENSION // 4])\n",
        "    img_2 = tf.image.resize(img, [DIMENSION // 2, DIMENSION // 2])\n",
        "    \n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        img_8 = tf.image.flip_left_right(img_8)\n",
        "        img_4 = tf.image.flip_left_right(img_4)\n",
        "        img_2 = tf.image.flip_left_right(img_2)\n",
        "        img = tf.image.flip_left_right(img)\n",
        "        \n",
        "            \n",
        "    return img_2, img_4, img_8, img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWCInvghC6lB"
      },
      "source": [
        "def process_path(file_path):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img_2, img_4, img_8, img = decode_img(img)\n",
        "    return img_2, img_4, img_8, img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4DVVYPYC8p0",
        "scrolled": true
      },
      "source": [
        "real_images_ds = real_images_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "synthetic_images_ds = synthetic_images_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYpPdZCvXhBZ"
      },
      "source": [
        "train_dataset = real_images_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8shCfRRmXhBa"
      },
      "source": [
        "test_dataset = synthetic_images_ds.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwO8UX5ODIXC"
      },
      "source": [
        "NUM_IMAGES = len(real_images_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwFbV3uPXhBa"
      },
      "source": [
        "NUM_IMAGES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSpp81TAYaFz"
      },
      "source": [
        "syn_img_2, syn_img_4, syn_img_8, syn_img = next(iter(test_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1vlvOt8XhBb"
      },
      "source": [
        "syn_img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC-OZ3xzZOXl"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, NUM_TEST_IMG, figsize=(DIMENSION,DIMENSION))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img.numpy())                       \n",
        "        ax.axis('off')    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoZj-728ZPl6"
      },
      "source": [
        "plotImages(syn_img[:NUM_TEST_IMG])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEvwTdQOXhBb"
      },
      "source": [
        "plotImages(syn_img_2[:NUM_TEST_IMG])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPvho1DnXhBc"
      },
      "source": [
        "plotImages(syn_img_4[:NUM_TEST_IMG])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FfPGdawXhBc"
      },
      "source": [
        "plotImages(syn_img_8[:NUM_TEST_IMG])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSXH1zxKXhBc"
      },
      "source": [
        "class ResizeNN(Layer):\n",
        "    def __init__(self, image_size=(512, 512), **kwargs):\n",
        "        self.image_size = image_size[0], image_size[1]\n",
        "        super(ResizeNN, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.image.resize(inputs, self.image_size, method='nearest')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.image_size[0], self.image_size[1], input_shape[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WsCRkBRXhBc"
      },
      "source": [
        "def disc_encoder():\n",
        "    input_shape = [DIMENSION,DIMENSION,3]\n",
        "    kernel= 3\n",
        "    filters = 64\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(inputs)\n",
        "    block_1 = tf.nn.elu(block_1)\n",
        "    \n",
        "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
        "    block_1 = tf.nn.elu(block_1)\n",
        "    block_1 = ResizeNN([DIMENSION, DIMENSION])(block_1)\n",
        "    \n",
        "    print(\"Encoder - Block 1 Created!\")\n",
        "    \n",
        "    block_2 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
        "    block_2 = tf.nn.elu(block_2)\n",
        "    \n",
        "    block_2 = Convolution2D(2*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
        "    block_2 = tf.nn.elu(block_2)\n",
        "    block_2 = ResizeNN([DIMENSION//2, DIMENSION//2])(block_2)\n",
        "    \n",
        "    print(\"Encoder - Block 2 Created!\")\n",
        "    \n",
        "    block_3 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
        "    block_3 = tf.nn.elu(block_3)\n",
        "    \n",
        "    block_3 = Convolution2D(3*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
        "    block_3 = tf.nn.elu(block_3)\n",
        "    block_3 = ResizeNN([DIMENSION//4, DIMENSION//4])(block_3)\n",
        "    \n",
        "    print(\"Encoder - Block 3 Created!\")\n",
        "    \n",
        "    block_4 = Convolution2D(4*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
        "    block_4 = tf.nn.elu(block_4)\n",
        "    \n",
        "    block_4 = Convolution2D(4*filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
        "    block_4 = tf.nn.elu(block_4)\n",
        "    block_4 = ResizeNN([DIMENSION//8, DIMENSION//8])(block_4)\n",
        "    \n",
        "    block_4_flatten  = Flatten()(block_4)\n",
        "    dense_1 = Dense(8*8*4*filters)(block_4_flatten)\n",
        "    dense_2 = Dense(FC_DIM)(dense_1)\n",
        "\n",
        "    outputs = (dense_2)   \n",
        "    \n",
        "    print(\"Encoder - Block 4 Created!\")\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs, name=\"disc_encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuhguzRIXhBd"
      },
      "source": [
        "def disc_decoder():\n",
        "    kernel= 3\n",
        "    filters = 64\n",
        "\n",
        "    inputs = Input(shape=(FC_DIM,))\n",
        "    \n",
        "    dense_1 = Dense(8*8*filters)(inputs)\n",
        "    dens_1_reshaped = Reshape([8,8,filters])(dense_1)\n",
        "    \n",
        "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(dens_1_reshaped)\n",
        "    block_1 = tf.nn.elu(block_1)\n",
        "    \n",
        "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
        "    block_1 = tf.nn.elu(block_1)\n",
        "    block_1 = ResizeNN([DIMENSION//4, DIMENSION//4])(block_1)\n",
        "    \n",
        "    print(\"Decoder - Block 1 Created!\")\n",
        "    \n",
        "    block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
        "    block_2 = tf.nn.elu(block_2)\n",
        "    \n",
        "    block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
        "    block_2 = tf.nn.elu(block_2)\n",
        "    block_2 = ResizeNN([DIMENSION//2, DIMENSION//2])(block_2)\n",
        "    \n",
        "    print(\"Decoder - Block 2 Created!\")\n",
        "    \n",
        "    block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
        "    block_3 = tf.nn.elu(block_3)\n",
        "    \n",
        "    block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
        "    block_3 = tf.nn.elu(block_3)\n",
        "    block_3 = ResizeNN([DIMENSION, DIMENSION])(block_3)\n",
        "    \n",
        "    print(\"Decoder - Block 3 Created!\")\n",
        "    \n",
        "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
        "    block_4 = tf.nn.elu(block_4)\n",
        "    \n",
        "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
        "    block_4 = tf.nn.elu(block_4)\n",
        "    \n",
        "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
        "    block_4 = tf.nn.elu(block_4)    \n",
        "    \n",
        "    block_4 = Convolution2D(3, (kernel, kernel), padding=\"same\")(block_4)\n",
        "    block_4 = Activation(\"sigmoid\")(block_4)\n",
        "\n",
        "    outputs = (block_4)   \n",
        "    \n",
        "    print(\"Decoder - Block 4 Created!\")\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs, name=\"disc_decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ9B7DFWZUKG"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    \n",
        "    e_model = disc_encoder()\n",
        "    d_model = disc_decoder()\n",
        "    \n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(e_model)\n",
        "    model.add(d_model)\n",
        "    \n",
        "    print(\"Discriminator - Model Generated!\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQfVloBPZWSb"
      },
      "source": [
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eqYgUcGZQoN"
      },
      "source": [
        "def make_generator_model( model_number = 1 ):\n",
        "    kernel= 3\n",
        "    filters = 64\n",
        "\n",
        "    input_image_8 = Input(shape=[DIMENSION//8,DIMENSION//8,3])\n",
        "    input_image_4 = Input(shape=[DIMENSION//4,DIMENSION//4,3])\n",
        "    input_image_2 = Input(shape=[DIMENSION//2,DIMENSION//2,3])\n",
        "    input_image   = Input(shape=[DIMENSION,DIMENSION,3])\n",
        "    \n",
        "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(input_image_8)\n",
        "    block_1 = tf.nn.elu(block_1)\n",
        "    \n",
        "    block_1 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
        "    block_1 = tf.nn.elu(block_1)\n",
        "    block_1 = ResizeNN([DIMENSION//4, DIMENSION//4])(block_1)\n",
        "    \n",
        "    print(\"Generator/Refiner - Block 1 Created!\")\n",
        "    \n",
        "    if ( model_number == 2 or model_number == 3 ):\n",
        "        block_2 = concatenate([input_image_4, block_1])\n",
        "        block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
        "    else:\n",
        "        block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_1)\n",
        "    block_2 = tf.nn.elu(block_2)\n",
        "    \n",
        "    block_2 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)\n",
        "    block_2 = tf.nn.elu(block_2)\n",
        "    block_2 = ResizeNN([DIMENSION//2, DIMENSION//2])(block_2)\n",
        "    \n",
        "    print(\"Generator/Refiner - Block 2 Created!\")\n",
        "    \n",
        "    if ( model_number == 3 ):\n",
        "        block_3 = concatenate([input_image_2, block_2])\n",
        "        block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)        \n",
        "    else:\n",
        "        block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_2)        \n",
        "        \n",
        "    block_3 = tf.nn.elu(block_3)\n",
        "    \n",
        "    block_3 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_3)\n",
        "    block_3 = tf.nn.elu(block_3)\n",
        "    block_4 = ResizeNN([DIMENSION, DIMENSION])(block_3)\n",
        "    \n",
        "    print(\"Generator/Refiner - Block 3 Created!\")\n",
        "\n",
        "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
        "    block_4 = tf.nn.elu(block_4)\n",
        "    \n",
        "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
        "    block_4 = tf.nn.elu(block_4)\n",
        "    \n",
        "    block_4 = Convolution2D(filters, (kernel, kernel), strides=(1,1), padding=\"same\")(block_4)\n",
        "    block_4 = tf.nn.elu(block_4)    \n",
        "    \n",
        "    block_4 = Convolution2D(3, (kernel, kernel), padding=\"same\")(block_4)\n",
        "    block_4 = Activation(\"sigmoid\")(block_4)\n",
        "\n",
        "    outputs = (block_4)   \n",
        "    \n",
        "    print(\"Generator/Refiner - Model Generated!\")\n",
        "\n",
        "    return Model(inputs=[input_image, input_image_2, input_image_4, input_image_8], outputs=outputs, name=\"refiner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EdxRbScXhBg"
      },
      "source": [
        "generator = make_generator_model(MODEL_NUMBER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqkOoKopXhBg"
      },
      "source": [
        "def calculate_LGAN(v, Dv):\n",
        "    \n",
        "    diff = tf.abs(v - Dv)\n",
        "    \n",
        "    return tf.reduce_mean(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k70E4DVOXhBg"
      },
      "source": [
        "def get_loss(k_t, x, D_x, G_z, D_G_z, outputs):\n",
        "    \n",
        "    lambda_r = 0.2\n",
        "    lambda_k = 0.001\n",
        "    gamma = 0.75\n",
        "    \n",
        "    LGAN_x = calculate_LGAN(x, D_x)\n",
        "    LGAN_gz = calculate_LGAN(G_z, D_G_z)\n",
        "    \n",
        "    D_v_hr = outputs\n",
        "    G_v_lr = G_z\n",
        "    LRCN_z = calculate_LGAN(D_v_hr, G_v_lr)\n",
        "    \n",
        "    D_loss = LGAN_x - k_t * LGAN_gz\n",
        "    G_loss = ( 1.0 - lambda_r ) * LGAN_gz + ( lambda_r ) * LRCN_z\n",
        "          \n",
        "    k_tp = k_t + lambda_k * (gamma * LGAN_x - LGAN_gz)\n",
        "        \n",
        "    return G_loss, D_loss, k_tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fiBmw-mZcgg"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE,)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7GnY6P_Zf1h"
      },
      "source": [
        " eval_input = [syn_img[:NUM_TEST_IMG], syn_img_2[:NUM_TEST_IMG], syn_img_4[:NUM_TEST_IMG], syn_img_8[:NUM_TEST_IMG]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdPXW8BrZh6y"
      },
      "source": [
        "def train_step(k_t, values):\n",
        "    \n",
        "    inputs_2, inputs_4, inputs_8, outptuts = values\n",
        "    \n",
        "    D_gen_in = [outptuts, inputs_2, inputs_4, inputs_8]\n",
        "    D_real_in = outptuts\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(D_gen_in, training=True)\n",
        "\n",
        "        d_generated_images = discriminator(generated_images, training=True)\n",
        "        discrimanted_images = discriminator(D_real_in, training=True)\n",
        "                \n",
        "        gen_loss, disc_loss, k_t = get_loss(k_t, D_real_in, discrimanted_images, generated_images, d_generated_images, outptuts)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)    \n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n",
        "    return k_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJk2q2hZuD7"
      },
      "source": [
        "def display_refined_images(model, synthetic_images):\n",
        "    \n",
        "    predictions = model(synthetic_images, training=False)\n",
        "    \n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    fig.suptitle('Synthetic Images', fontsize=16)\n",
        "    for i in range(synthetic_images[0].shape[0]):\n",
        "        \n",
        "        plt.subplot(4, 4, i+1)        \n",
        "        plt.imshow(synthetic_images[0][i, :, :] )            \n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    fig.suptitle('Refined Images', fontsize=16)\n",
        "    for i in range(predictions.shape[0]):\n",
        "        \n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :] )            \n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8YH9c0CZwZD"
      },
      "source": [
        "STEP_SIZE = NUM_IMAGES // BATCH_SIZE\n",
        "\n",
        "def train(epochs):\n",
        "    \n",
        "    k_t = 0.0    \n",
        "    \n",
        "    step = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        start = time.time()\n",
        "        \n",
        "        g_loss = 0\n",
        "        d_loss = 0\n",
        "\n",
        "        for _ in range(STEP_SIZE):\n",
        "            \n",
        "            k_t = min(max(k_t, 0.0), 1.0)\n",
        "            \n",
        "            k_t = train_step(k_t, next(iter(train_dataset)))\n",
        "            step += 1\n",
        "            \n",
        "            if ( step % 100 == 0 ):\n",
        "                \n",
        "                display.clear_output(wait=True)\n",
        "                display_refined_images(generator, eval_input)\n",
        "                        \n",
        "        print ('{} seconds for epoch {}/{}'.format(time.time()-start, epoch + 1, epochs))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    display_refined_images(generator, eval_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJNQT51KZyL3",
        "scrolled": false
      },
      "source": [
        "%%time\n",
        "train(EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7q3HA__XhBi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}